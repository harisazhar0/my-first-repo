# -*- coding: utf-8 -*-
"""Simple_Linear_Regression_&_MLR_ (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Snb8BS2LRQws_rOnQczlvleTKxFiM8F8
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

df = pd.read_csv("/content/placement (1).csv")

df

plt.scatter(df['cgpa'],df['package'])
plt.xlabel('CGPA')
plt.ylabel('Package')

X = df.iloc[:,0:1] ##[rows:rows,cols:cols]
y = df.iloc[:,-1]

X

"""during train test split x and y columns are divided into training and testing datasets"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 2)

x_test

x_train.shape

x_test.shape

df



from sklearn.linear_model import LinearRegression

lr = LinearRegression() ## making object of model

lr.fit(x_train,y_train) ## fit means to train model on some data

df.head(2)

## predicting package
lr.predict([[5.12]])

"""## our model has learned the patterns in data and made equation

## testing dataset
"""

## i have trained model on training data now testing on testing data
predictions = lr.predict(x_test)

x_test

y_test ## actual value

predictions

plt.scatter(df['cgpa'],df['package']) ## scatter plot
plt.plot(x_train,lr.predict(x_train),color = 'red') ##
plt.xlabel('CGPA')
plt.ylabel('Package')

m = lr.coef_ ##coefficient
m

b = lr.intercept_
b

# y = mx + b
## m is the slope and b is the intercept

m * 5.5 + b

lr.predict([[5.5]])

m * 8.5 + b

df.head(2)



x = df.iloc[:,0].values
y = df.iloc[:,-1].values



"""##Simple Linear regression class self implelmented"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state = 2)

class MeraLR:
  def _init_(self):
    self.m =0
    self.b=0
  def fit(self,x_train,y_train):
    num =0
    den =0
    for i in range(x_train.shape[0]):
       num = num + ((x_train[i]-x_train.mean())*(y_train[i]-y_train.mean()))
       den = den + ((x_train[i]-x_train.mean())*(x_train[i]-x_train.mean()))
    self.m = num/den
    self.b = y_train.mean()- (self.m*x_train.mean())
  def predict(self,x_test):
      print("slope is :"+ str(self.m))
      print("y_intercept is "+ str(self.b))
      return self.m*x_test +self.b

lr = MeraLR()

lr.fit(x_train,y_train)

lr.predict(x_test)

from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score

y_pred = lr.predict(x_test)

y_pred

print("MAE",mean_absolute_error(y_test,y_pred))

print("MSE",mean_squared_error(y_test,y_pred))

0.2884710931878174**2

print("RMSE",np.sqrt(mean_squared_error(y_test,y_pred))) ## root mean squared error

r2=r2_score(y_test,y_pred)

r2



import numpy as np
from sklearn.datasets import load_diabetes

X,y = load_diabetes(return_X_y=True) ## storing all input values in x and output in y

X

X.shape

y.shape

"""## Using Sklearn's Linear Regression"""

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)

print(X_train.shape)
print(X_test.shape)

from sklearn.linear_model import LinearRegression

reg = LinearRegression()
reg.fit(X_train,y_train) ## fit means training

y_pred = reg.predict(X_test) ## we are predicting values on x_test

from sklearn.metrics import r2_score

r2_score(y_test,y_pred)

reg.coef_

reg.intercept_

"""## Making our own Multiple Linear Regression Class"""

X_train

class MeraLR():
  def __init__(self):
    self.coef_ = None
    self.intercept_ =None
  def fit(self,X_train,y_train):
    X_train = np.insert(X_train,0,1,axis=1)
    #calcualte intercerps and coefs
    betas = np.linalg.inv(np.dot(X_train.T,X_train)).dot(X_train.T).dot(y_train)
    self.intercept_ =betas[0]
    self.coef_ =betas[1:]
  def predict(self,X_test):
    y_pred = np.dot(X_test,self.coef_)+self.intercept_
    return y_pred

lr=MeraLR()

lr.fit(X_train,y_train)

r2_score(y_test,y_pred)

lr.coef_

lr.intercept_

